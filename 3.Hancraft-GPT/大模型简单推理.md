# LLMç”Ÿæˆ/é¢„æµ‹

å¤§æ¨¡å‹çš„ç”Ÿæˆè¿‡ç¨‹æœ¬è´¨ä¸Šæ˜¯ä¸€ç§æ¦‚ç‡é‡‡æ ·æœºåˆ¶ã€‚åœ¨è¿™ä¸ªè¿‡ç¨‹ä¸­ï¼Œæ¨¡å‹æ ¹æ®è¾“å…¥ä¿¡æ¯é¢„æµ‹æ¯ä¸ªè¯æ±‡å‡ºç°çš„æ¦‚ç‡ï¼Œå¹¶é€æ­¥ç”Ÿæˆæ–‡æœ¬ã€‚å› æ­¤ï¼Œé€‰æ‹©åˆé€‚çš„è§£ç ç­–ç•¥è‡³å…³é‡è¦ï¼Œå› ä¸ºå®ƒç›´æ¥å½±å“åˆ°ç”Ÿæˆå†…å®¹çš„è´¨é‡å’Œè¿è´¯æ€§ã€‚

è§£ç ç­–ç•¥ä¸ä»…å†³å®šäº†ç”Ÿæˆçš„æ–‡æœ¬æ˜¯å¦ç¬¦åˆä¸Šä¸‹æ–‡çš„é€»è¾‘ï¼Œè¿˜å½±å“åˆ°æ–‡æœ¬çš„å¤šæ ·æ€§å’Œåˆ›é€ æ€§ã€‚ä¸åŒçš„è§£ç ç­–ç•¥ï¼Œå¦‚è´ªå¿ƒæœç´¢ã€æŸæœç´¢å’Œé‡‡æ ·æ–¹æ³•ï¼ˆå¦‚top-kå’Œæ ¸é‡‡æ ·ï¼‰ï¼Œåœ¨è¾“å‡ºå†…å®¹æ—¶å±•ç°å‡ºä¸åŒçš„ç‰¹ç‚¹ã€‚ä¾‹å¦‚ï¼Œè´ªå¿ƒæœç´¢å¯èƒ½ä¼šå¿«é€Ÿæ‰¾åˆ°ä¸€ä¸ªå¯è¡Œçš„è¾“å‡ºï¼Œä½†å¯èƒ½ç¼ºä¹å¤šæ ·æ€§ï¼›è€ŒæŸæœç´¢åˆ™èƒ½å¤Ÿåœ¨ç”Ÿæˆè¿‡ç¨‹ä¸­ä¿æŒå¤šä¸ªå€™é€‰æ–‡æœ¬ï¼Œä»è€Œæé«˜è¾“å‡ºçš„è´¨é‡ã€‚

## è¯­è¨€æ¨¡å‹ç”Ÿæˆæ–‡æœ¬è¿‡ç¨‹æè¿°

è¯­è¨€æ¨¡å‹é€šè¿‡æ ¹æ®è¾“å…¥ä¸Šä¸‹æ–‡é¢„æµ‹åºåˆ—ä¸­çš„ä¸‹ä¸€ä¸ªtokenæ¥ç”Ÿæˆæ–‡æœ¬ã€‚æ­¤è¿‡ç¨‹å§‹äºå°†è¾“å…¥æ–‡æœ¬åˆ†è§£ä¸ºå¯ç®¡ç†çš„ç‰‡æ®µæˆ–tokenã€‚

tokenå¯ä»¥æ˜¯å•ä¸ªå­—ç¬¦æˆ–æ•´ä¸ªå•è¯æˆ–çŸ­è¯­ï¼Œå…·ä½“å–å†³äºæ¨¡å‹çš„è®¾è®¡ä»¥åŠæ•æ‰çš„è¯­è¨€ç»†èŠ‚æ°´å¹³ã€‚è¯çº§tokenizerå°†æ–‡æœ¬åˆ†å‰²ä¸ºå®Œæ•´å•è¯ï¼Œè€Œå­è¯tokenizeråˆ™å°†å•è¯åˆ†è§£ä¸ºæ›´å°çš„å•ä½ï¼Œå¦‚å‰ç¼€ã€è¯æ ¹å’Œåç¼€ã€‚å­è¯tokenizeråœ¨è¯æ±‡å¤§å°å’Œå¤„ç†æœªçŸ¥è¯æ±‡çš„èƒ½åŠ›ä¹‹é—´å–å¾—äº†å¹³è¡¡ã€‚

æ¯ä¸ªtokenç”±ä¸€ä¸ªæ•´æ•°è¡¨ç¤ºï¼Œå°†å…¶æ˜ å°„åˆ°æ¨¡å‹è¯æ±‡ä¸­çš„å”¯ä¸€æ ‡è¯†ç¬¦ã€‚è¯¥è¯æ±‡æ˜¯æ¨¡å‹è¯†åˆ«çš„æ‰€æœ‰å”¯ä¸€tokençš„é¢„å®šä¹‰åˆ—è¡¨ï¼Œç±»ä¼¼äºè¯­è¨€å­—å…¸ã€‚ä¾‹å¦‚ï¼Œâ€œbeyondâ€å¯èƒ½è¢«åˆ†é…ä¸ºæ•´æ•°1234ï¼Œè€Œå­è¯â€œbeâ€å¯èƒ½è¢«åˆ†é…ä¸º5678ã€‚

åœ¨tokenizeä¹‹åï¼Œtokençš„æ•°å€¼è¡¨ç¤ºå°†ç”±æ¨¡å‹å¤„ç†ï¼Œå…¶ä¸­åŒ…æ‹¬ç¥ç»ç½‘ç»œå±‚å’ŒTransformerä¸­çš„è‡ªæ³¨æ„åŠ›æœºåˆ¶ã€‚è¿™äº›ç»„ä»¶ååŒå·¥ä½œä»¥é¢„æµ‹åºåˆ—ä¸­çš„ä¸‹ä¸€ä¸ªtokenã€‚

åœ¨æœ€åä¸€å±‚ä¸­ï¼Œæ¨¡å‹å°†è¾“å…¥åºåˆ—è½¬æ¢ä¸ºlogitå‘é‡ï¼Œæ¯ä¸ªæ¡ç›®è¡¨ç¤ºè¯æ±‡ä¸­æ¯ä¸ªtokençš„å¾—åˆ†ã€‚è¿™äº›logitsæŒ‡ç¤ºæ¯ä¸ªtokenåœ¨åºåˆ—ä¸­ä½œä¸ºä¸‹ä¸€ä¸ªtokençš„å¯èƒ½æ€§ï¼Œä½†å®ƒä»¬ä¸æ˜¯æ¦‚ç‡ä¸”æ€»å’Œä¸ç­‰äº1ã€‚

![img](./assets/81eb7e247f614e7c9872cf85d4d57af4.png)

softmaxå‡½æ•°å°†logitsè½¬æ¢ä¸ºæ¦‚ç‡ã€‚å®ƒå°†logitsç¼©æ”¾åˆ°0å’Œ1ä¹‹é—´ï¼Œä½¿å…¶å€¼æ€»å’Œä¸º1ï¼Œä»è€Œå½¢æˆæ•´ä¸ªè¯æ±‡ä¸­æ‰€æœ‰å¯èƒ½ä¸‹ä¸€ä¸ªtokençš„æ¦‚ç‡åˆ†å¸ƒã€‚ä¾‹å¦‚ï¼Œå¦‚æœå½“å‰åºåˆ—ä¸ºâ€œThe basketball team clinchedâ€ï¼Œæ¨¡å‹å¯èƒ½é¢„æµ‹ä¸‹ä¸€ä¸ªtokenä¸ºâ€œtheâ€çš„æ¦‚ç‡ä¸º0.298ï¼Œâ€œtheirâ€ä¸º0.213ï¼Œâ€œanotherâ€ä¸º0.125ï¼Œç­‰ç­‰ã€‚

 æ³¨æ„Logitsæ˜¯æœºå™¨å­¦ä¹ æ¨¡å‹æœ€åä¸€å±‚è¾“å‡ºçš„åŸå§‹æœªå½’ä¸€åŒ–å¾—åˆ†ï¼Œåœ¨åº”ç”¨ä»»ä½•æ¿€æ´»å‡½æ•°ä¹‹å‰ã€‚è¿™äº›å¾—åˆ†è¡¨ç¤ºæ¨¡å‹å¯¹æ¯ä¸ªå¯èƒ½ç»“æœçš„ä¿¡å¿ƒã€‚ç„¶è€Œï¼Œç”±äºlogitsä¸æ˜¯æ¦‚ç‡ï¼Œå®ƒä»¬çš„æ€»å’Œä¸ç­‰äº1ï¼Œå¹¶ä¸”ä¸èƒ½ç›´æ¥è§£é‡Šã€‚

åœ¨è®¡ç®—æ¦‚ç‡åï¼Œæ¨¡å‹æ ¹æ®è¿™äº›æ¦‚ç‡ä½¿ç”¨å„ç§è§£ç ç­–ç•¥é€‰æ‹©ä¸‹ä¸€ä¸ªtokenã€‚è¿™äº›ç­–ç•¥ä»ç®€å•åœ°é€‰æ‹©æœ€å¯èƒ½çš„tokenåˆ°æ›´å¤æ‚çš„æ–¹æ³•ï¼ˆå¦‚å¼•å…¥éšæœºæ€§æˆ–è€ƒè™‘å¤šä¸ªé¡¶çº§å€™é€‰é¡¹ï¼‰å„ä¸ç›¸åŒã€‚æ‰€é€‰tokenä¼šè¢«æ·»åŠ åˆ°ç°æœ‰åºåˆ—ä¸­ï¼Œç„¶åä½œä¸ºæ–°è¾“å…¥åé¦ˆç»™æ¨¡å‹ã€‚è¿™ä¸ªè¿‡ç¨‹é‡å¤è¿›è¡Œï¼šæ¨¡å‹å¤„ç†æ‰©å±•åçš„åºåˆ—ï¼Œç”Ÿæˆä¸€ç»„æ–°çš„logitså’Œæ¦‚ç‡ï¼Œå¹¶é€‰æ‹©ä¸‹ä¸€ä¸ªtokenã€‚è¿™ä¸ªå¾ªç¯æŒç»­ï¼Œç›´åˆ°æ»¡è¶³åœæ­¢æ¡ä»¶ï¼Œä¾‹å¦‚è¾¾åˆ°æœ€å¤§åºåˆ—é•¿åº¦æˆ–ç”Ÿæˆç‰¹æ®Šçš„ç»“æŸtokenã€‚

<img src="./assets/2ad14ec345054b489fd26a1f4b75bb96.png" alt="img" style="zoom:50%;" />

## é¢„æµ‹æµç¨‹-æ‰‹æ’•

ç±»ä¼¼äºåˆ†ç±»å™¨é€šå¸¸ä¼šé€‰æ‹©æ¦‚ç‡æœ€å¤§çš„æ ‡ç­¾ï¼Œå¯¹äºæ–‡æœ¬ç”Ÿæˆä»»åŠ¡ï¼Œæœ€ç›´æ¥çš„æ–¹æ³•å°±æ˜¯æ¯æ¬¡å–æ¦‚ç‡æœ€å¤§çš„token_idï¼Œæ¥ä¸‹æ¥æˆ‘ä»¥è´ªå¿ƒæœç´¢ä¸ºä¾‹ä»‹ç»æ–‡æœ¬ç”Ÿæˆçš„æµç¨‹ã€‚

LLMçš„logitæ˜¯batch size * seq length * token numï¼Œ**åœ¨è®­ç»ƒæ—¶ï¼Œæ¨¡å‹é€šå¸¸æ˜¯ç”¨ç¬¬ i-1 ä½çš„ logit å»é¢„æµ‹ç¬¬ i ä½çš„ token idï¼Œæ‰€ä»¥é¢„æµ‹æ—¶ç”¨æœ€åä¸€ä½çš„ logit å»é¢„æµ‹æ–°çš„ token id**ï¼Œç»“æœsoftrmaxåï¼Œæˆ‘ä»¬å¾—åˆ°æ–°çš„ token idï¼Œç„¶å**æŒ‰ç…§ auto regressive çš„é£æ ¼ï¼ŒæŠŠæ–° token idåŠ å…¥åˆ° ä¹‹å‰çš„ token id åºåˆ—ä¸­ï¼Œ å†ç”¨ç›¸åŒçš„æ–¹æ³•å¾—åˆ°ä¸‹ä¸€ä¸ª token id**ã€‚è¿™å°±æ˜¯é¢„æµ‹çš„æ•´ä½“æµç¨‹ï¼Œ è´ªå¿ƒæœç´¢åªä¸è¿‡å†³å®šäº†æ–°çš„ token id çš„é€‰æ‹©ã€‚

```python
import os
import json
import torch
import argparse
from tqdm import tqdm
from pprint import pprint

from transformers import AutoTokenizer, AutoModelForCausalLM

DEVICE = torch.device("cuda:7" if torch.cuda.is_available() else "cpu")


# local_cache_dir is for mannually downloading model params to local env
local_cache_dir = "../../DataCollection/officials/gpt2"
model = AutoModelForCausalLM.from_pretrained(local_cache_dir, output_hidden_states=True).to(DEVICE)
tokenizer = AutoTokenizer.from_pretrained(local_cache_dir)

# Encode initial input
input_text = "What is star war?"
input_ids = tokenizer.encode(input_text, return_tensors='pt').to(DEVICE)  # Shape: [1, 4]

# Set the number of tokens to generate
num_tokens_to_generate = 100

# Iteratively generate tokens
# for _ in tqdm(range(num_tokens_to_generate), mininterval=1):
for _ in range(num_tokens_to_generate):

    # Get model output logits
    outputs = model(input_ids)  # Shape: [1, current_length, 50257] or [batch_size, token length, vocab size]
    logits = outputs.logits

    '''
    Predict the next token based on the last position
    i.e., the i-th position logits is for predicting the i+1-th token
    In this case, we want to predict the next token based on previous tokens, so we use the logits of the final token.
    If you see the source code of forward function, you can notice the shifting of labels and logits for aligning.
    '''
    next_token_logits = logits[:, -1, :]  # Shape: [1, 50257], corresponding to each vocab

    '''
    Greedy decoding: select the token with the highest probability
    Supposily you can try top-k and beam search
    '''
    greedy_token_id = torch.argmax(next_token_logits, dim=-1)  # Shape: [1]

    # Append the predicted token to the input_ids
    input_ids = torch.cat([input_ids, greedy_token_id.unsqueeze(-1)], dim=-1).to(DEVICE)  # Shape: [1, current_length + 1]

    # print(tokenizer.decode(input_ids.squeeze(), skip_special_tokens=True))

# Decode the entire sequence of tokens
generated_text = tokenizer.decode(input_ids.squeeze(), skip_special_tokens=True)
print("Generated Text:\n", generated_text)
```



ä»¥ä¸‹æ˜¯ decode åçš„é¢„æµ‹ç»“æœã€‚

```python
Generated Text:
 What is star war?

Star wars are the most common form of warfare in the world. The most common form of warfare is the war of attrition. The most common form of warfare is the war of attrition.

Star wars are the most common form of warfare in the world. The most common form of warfare is the war of attrition. The most common form of warfare is the war of attrition.

Star wars are the most common form of warfare in the world. The most common form of warfare is
```



# è§£ç ç­–ç•¥

è§£ç ç­–ç•¥å†³å®šäº†è¯­è¨€æ¨¡å‹åœ¨é¢„æµ‹æ‰€æœ‰å¯èƒ½tokençš„æ¦‚ç‡åå¦‚ä½•é€‰æ‹©ä¸‹ä¸€ä¸ªtokenã€‚è¿™äº›ç­–ç•¥å¯¹ç”Ÿæˆæ–‡æœ¬çš„è´¨é‡å’Œå¤šæ ·æ€§æœ‰å¾ˆå¤§å½±å“ã€‚è§£ç ç­–ç•¥ä¸»è¦åˆ†ä¸ºä¸¤ç±»ï¼šç¡®å®šæ€§å’Œéšæœºæ€§ã€‚

- **ç¡®å®šæ€§ç­–ç•¥**ï¼šåœ¨ç›¸åŒè¾“å…¥ä¸‹ï¼Œç¡®å®šæ€§ç­–ç•¥å°†å§‹ç»ˆç”Ÿæˆç›¸åŒçš„è¾“å‡ºï¼Œä¸æ¶‰åŠä»»ä½•éšæœºæ€§ã€‚
- **éšæœºç­–ç•¥**ï¼šåœ¨é€‰æ‹©è¿‡ç¨‹ä¸­å¼•å…¥éšæœºæ€§ï¼Œæ—¨åœ¨äº§ç”Ÿæ›´ä¸°å¯Œå’Œåˆ›é€ æ€§çš„è¾“å‡ºï¼Œä½†å¯é¢„æµ‹æ€§è¾ƒä½ã€‚

## ç¡®å®šæ€§ç­–ç•¥

### è´ªå¿ƒæœç´¢ Greedy Search

```python
# encode context the generation is conditioned on
model_inputs = tokenizer('I enjoy walking with my cute dog', return_tensors='pt').to(DEVICE)

pprint(model_inputs, width=100)
```

è´ªå¿ƒæœç´¢æ˜¯ä¸€ç§è§£ç æ–¹æ³•ï¼Œåœ¨æ¯ä¸ªæ­¥éª¤ä¸­é€‰æ‹©æœ€å¯èƒ½çš„tokenä½œä¸ºä¸‹ä¸€ä¸ªtokenã€‚è¿™æ„å‘³ç€å®ƒå§‹ç»ˆé€‰æ‹©æ¯ä¸ªé˜¶æ®µæ¦‚ç‡æœ€é«˜çš„tokenï¼Œå¿½ç•¥æ‰€æœ‰å…¶ä»–å¯èƒ½çš„é€‰é¡¹ã€‚

**ä¼˜ç‚¹**ï¼š

- **æ•ˆç‡**ï¼šè´ªå¿ƒè§£ç ç®€å•ä¸”å¿«é€Ÿï¼Œé€‚ç”¨äºé€Ÿåº¦æ•æ„Ÿçš„åº”ç”¨ã€‚
- **ä½è®¡ç®—æˆæœ¬**ã€‚

**ç¼ºç‚¹**ï¼š

- **é‡å¤æ€§**ï¼šå¾€å¾€ç”Ÿæˆé‡å¤å’Œå¯é¢„æµ‹çš„æ–‡æœ¬ã€‚
- **ç¼ºä¹åˆ›é€ æ€§**ï¼šæ€»æ˜¯é€‰æ‹©æœ€å¯èƒ½çš„ä¸‹ä¸€ä¸ªtokenï¼Œæœªè€ƒè™‘æ›´å¹¿æ³›çš„ä¸Šä¸‹æ–‡æˆ–æ›¿ä»£é€‰é¡¹ï¼Œå¯èƒ½é™ä½æ–‡æœ¬è´¨é‡å’Œå¤šæ ·æ€§ã€‚



```python
# generate 40 new tokens
# the output of generate is a `GenerateDecoderOnlyOutput` object, we only need the first attribute.
greedy_output = model.generate(**model_inputs, 
    max_new_tokens=40, 
    # max_length=50, 
    )

token_ids = torch.squeeze(greedy_output[0])
print(tokenizer.decode(token_ids, skip_special_tokens=True))
```



```python
I enjoy walking with my cute dog, but I'm not sure if I'll ever be able to walk with my dog. I'm not sure if I'll ever be able to walk with my dog.

I'm not sure
```



åœ¨ç»™å®šä¸Šä¸‹æ–‡ç”Ÿæˆçš„è¯è¯­æ˜¯åˆç†çš„ï¼Œä½†æ¨¡å‹å¾ˆå¿«å¼€å§‹é‡å¤è‡ªå·±ï¼è¿™æ˜¯è¯­è¨€ç”Ÿæˆä¸­ä¸€ä¸ªéå¸¸å¸¸è§çš„é—®é¢˜ï¼Œå°¤å…¶åœ¨è´ªå©ªæœç´¢å’Œæ³¢æŸæœç´¢ä¸­æ›´ä¸ºæ˜æ˜¾ã€‚

ç„¶è€Œï¼Œè´ªå©ªæœç´¢çš„ä¸»è¦ç¼ºç‚¹æ˜¯**å®ƒä¼šé”™è¿‡é‚£äº›è¢«ä½æ¦‚ç‡è¯é®æŒ¡çš„é«˜æ¦‚ç‡è¯**ã€‚å…¶å®æ˜¯å› ä¸ºå®ƒçš„**è§†é‡çª—å£åªæœ‰1ï¼Œå› æ­¤æ— æ³•åšå‡ºåé•¿è¿œçš„åˆ¤æ–­**ã€‚

é’ˆå¯¹è´ªå¿ƒæœç´¢çš„å±€é™æ€§è¿›è¡Œæ”¹è¿›æœ‰ä»¥ä¸‹å‡ ç§æ–¹æ¡ˆï¼š

1. æŸæœç´¢ï¼ˆBeam Searchï¼‰ï¼šè¯¥æ–¹æ³•é€šè¿‡ä¿ç•™å‰ n ä¸ªæœ€é«˜æ¦‚ç‡çš„å¥å­æ¥é¿å…å±€éƒ¨æœ€ä¼˜çš„é—®é¢˜ã€‚å½“ n = 1 æ—¶ï¼ŒæŸæœç´¢å˜ä¸ºè´ªå¿ƒæœç´¢ã€‚æ¯ä¸€æ­¥é€‰æ‹©è”åˆæ¦‚ç‡æœ€é«˜çš„å€™é€‰å¥å­ï¼Œæœ€ç»ˆé€‰å‡ºæ•´ä½“ç”Ÿæˆæ¦‚ç‡æœ€é«˜çš„å¥å­ã€‚

2. é•¿åº¦æƒ©ç½šï¼ˆLength Penaltyï¼‰ï¼š é€šè¿‡åœ¨ç”Ÿæˆæ¦‚ç‡è®¡ç®—ä¸­å¼•å…¥é•¿åº¦æƒ©ç½šï¼Œé¿å…ç”Ÿæˆè¾ƒçŸ­å¥å­çš„å€¾å‘ã€‚å…·ä½“åšæ³•æ˜¯å°†å¥å­æ¦‚ç‡é™¤ä»¥å…¶é•¿åº¦çš„æŒ‡æ•°å¹‚ Î±ï¼Œé¼“åŠ±ç”Ÿæˆæ›´é•¿çš„å¥å­ã€‚

3. é‡å¤æƒ©ç½šï¼ˆRepetition Penaltyï¼‰ï¼š  ä½¿ç”¨ n-å…ƒæƒ©ç½šæ¥å‡å°‘é‡å¤ç”Ÿæˆçš„è¯å…ƒã€‚å‡ºç°æƒ©ç½šå’Œé¢‘ç‡æƒ©ç½šæ˜¯æ›´â€œæ¸©å’Œâ€çš„ç­–ç•¥ï¼Œåˆ†åˆ«é€šè¿‡é™ä½å·²ç”Ÿæˆè¯å…ƒçš„æ¦‚ç‡æ¥å‡å°‘é‡å¤çš„å¯èƒ½æ€§ã€‚


### æŸæœç´¢

**Beam search é€šè¿‡åœ¨æ¯ä¸ªæ—¶é—´æ­¥ä¿ç•™æœ€å¯èƒ½çš„ num_beams ä¸ªå‡è®¾**ï¼Œæœ€ç»ˆé€‰æ‹©æ€»ä½“æ¦‚ç‡æœ€é«˜çš„å‡è®¾ï¼Œä»è€Œé™ä½äº†é—æ¼éšè—çš„é«˜æ¦‚ç‡è¯åºåˆ—çš„é£é™©ã€‚åœ¨æ¯ä¸ªæ—¶é—´æ­¥éª¤ç»´æŒä¸€ä¸ªåŒ…å« K ä¸ªæœ€æœ‰å¯èƒ½åºåˆ—çš„æŸï¼Œå…¶ä¸­ K è¢«ç§°ä¸ºæŸå®½åº¦ã€‚è¿™ä¸ªè¿‡ç¨‹ä¼šæŒç»­è¿›è¡Œï¼Œç›´åˆ°è¾¾åˆ°é¢„å®šä¹‰çš„æœ€å¤§é•¿åº¦æˆ–å‡ºç°ç»“æŸåºåˆ—æ ‡è®°ã€‚è¿™ç§æ–¹æ³•ç”Ÿæˆçš„æ–‡æœ¬è´¨é‡æ›´é«˜ï¼Œå…·ä½“å–å†³äºæŸçš„å¤§å°ï¼Œä½†ç”±äºè®¡ç®—é‡æ¯”è´ªå¿ƒæœç´¢æ›´å¤šï¼Œå¯èƒ½ä¼šè¾ƒæ…¢ã€‚

![img](./assets/e2e2f801a0b542f694cf7bcb1d404f8c.png)

ä»¥ä¸Šå›¾ä¸ºä¾‹ï¼Œæˆ‘ä»¬ä»ç»™å®šçš„åºåˆ—â€œOnce upon a timeâ€å¼€å§‹ï¼Œå¯¹äºæŸå®½åº¦ K=2ï¼Œä¸‹ä¸€ä¸ªæœ€å¯èƒ½çš„ä¸¤ä¸ªè¯å…ƒæ˜¯â€œaâ€å’Œâ€œtheâ€ã€‚åœ¨ä¸‹ä¸€æ¬¡è¿­ä»£ä¸­ï¼Œæˆ‘ä»¬æœ‰ä¸¤ä¸ªåºåˆ—ï¼ˆâ€œaâ€, â€œcatâ€ï¼‰ï¼Œå…¶æ¦‚ç‡ä¸º 0.20ï¼ˆ0.5Ã—0.4ï¼‰ï¼Œè¿˜æœ‰ä¸€ä¸ªåºåˆ—ï¼ˆâ€œtheâ€, â€œpeopleâ€ï¼‰ï¼Œå…¶æ¦‚ç‡æ›´é«˜ä¸º 0.21ï¼ˆ0.3Ã—0.7ï¼‰ã€‚å› æ­¤ï¼ŒæŸæœç´¢å¯ä»¥é€‰æ‹©æ¦‚ç‡æ›´é«˜çš„åºåˆ—â€œthe peopleâ€ä½œä¸ºç”Ÿæˆåºåˆ—ã€‚å¦‚æœæˆ‘ä»¬å¢åŠ æŸå®½åº¦ Kï¼Œç®—æ³•å¯ä»¥æ¢ç´¢æ›´å¤šçš„åºåˆ—ï¼Œä»è€Œç”Ÿæˆæ›´é«˜è´¨é‡çš„æ–‡æœ¬ï¼Œä½†è¿™ä¼šå¢åŠ è®¡ç®—æˆæœ¬ã€‚å› æ­¤ï¼Œè¿™ä¸¤è€…ä¹‹é—´å­˜åœ¨æƒè¡¡ã€‚

Beam search æ€»èƒ½æ‰¾åˆ°æ¯”è´ªå¿ƒæœç´¢ï¼ˆgreedy searchï¼‰å…·æœ‰æ›´é«˜æ¦‚ç‡çš„è¾“å‡ºåºåˆ—ï¼ˆä¸€ä¸ªèŒƒå›´å†…çš„æ¦‚ç‡ä¹˜æœºæ›´é«˜ï¼Œå› ä¸º **Beam search çš„è§†é‡æ¯”è´ªå¿ƒæœç´¢æ›´è¿œ**ï¼‰ï¼Œä½†å¹¶ä¸èƒ½ä¿è¯æ‰¾åˆ°æœ€å¯èƒ½çš„è¾“å‡ºã€‚

```python
# activate beam search and early_stopping
beam_output = model.generate(
    **model_inputs,
    max_new_tokens=40,
    num_beams=5,
    early_stopping=True
)

token_ids = torch.squeeze(beam_output[0])
print(tokenizer.decode(token_ids, skip_special_tokens=True))
```

```python
I enjoy walking with my cute dog, but I'm not sure if I'll ever be able to walk with him again.

I'm not sure if I'll ever be able to walk with him again. I'm not sure
```

å°½ç®¡ç»“æœå¯èƒ½æ›´æµç•…ï¼Œä½†è¾“å‡ºä»ç„¶åŒ…å«ç›¸åŒè¯åºåˆ—çš„é‡å¤ã€‚ä¸€ä¸ªç®€å•çš„è§£å†³æ–¹æ³•æ˜¯å¼•å…¥ n-gram æƒ©ç½šï¼ˆå³è¯åºåˆ—æƒ©ç½šï¼‰ã€‚**æœ€å¸¸è§çš„ n-gram æƒ©ç½šé€šè¿‡æ‰‹åŠ¨å°†å¯èƒ½äº§ç”Ÿå·²å‡ºç°è¿‡çš„ n-gram çš„ä¸‹ä¸€ä¸ªè¯çš„æ¦‚ç‡è®¾ä¸º 0ï¼Œä»è€Œç¡®ä¿ä¸ä¼šæœ‰ n-gram é‡å¤å‡ºç°**ã€‚

### n-gramæƒ©ç½š-é¿å…æ–‡æœ¬å¤§é‡é‡å¤

 é‡å¤æƒ©ç½šæ˜¯ä¸ºäº†é™ä½ç”Ÿæˆé‡å¤è¯å…ƒçš„æ¦‚ç‡ï¼Œå¯ä»¥é€šè¿‡ n-å…ƒæƒ©ç½šæˆ–å…¶ä»–æœºåˆ¶æ¥å®ç°ã€‚å¯¹äº n-å…ƒæƒ©ç½šï¼Œå…¬å¼ä¸ºï¼š
$$
P_{\text{penalized}}(w) = P(w) \times (1 - \text{Penalty}(n))
$$
Penalty(n) æ˜¯åŸºäºå½“å‰ç”Ÿæˆçš„é‡å¤ n-å…ƒè¯çš„æƒ©ç½šå€¼ã€‚å…¶ä»–æƒ©ç½šæœºåˆ¶æœ‰å‡ºç°æƒ©ç½šï¼ˆPresence Penaltyï¼‰å’Œé¢‘ç‡æƒ©ç½šï¼ˆFrequency Penaltyï¼‰ã€‚

![P_{\text{adjusted}}(w) = P(w) - \alpha \times \text{count}(w)](./assets/text{count}(w).png)

![P_{\text{adjusted}}(w) = P(w) - \alpha \times \text{frequency}(w)](./assets/text{frequency}(w).png)

```python
# introduce n-grams (a.k.a word sequences of n words) penalties
# by default, this penalty will set the possibiliy to 0
# The repetition_penalty parameter can be set to discourage the model from generating repeated n-grams. A value greater than 1.0 penalizes repetition. 
beam_output = model.generate(
    **model_inputs,
    max_new_tokens=40,
    num_beams=5,
    no_repeat_ngram_size=2,
    repetition_penalty=1.5,
    early_stopping=True
)

print("[Output (Beam Search)(n-grams penalty)]: ")
token_ids = torch.squeeze(beam_output[0])
print(tokenizer.decode(token_ids, skip_special_tokens=True))
```



```python
Setting `pad_token_id` to `eos_token_id`:None for open-end generation.
[Output (Beam Search)(n-grams penalty)]: 
I enjoy walking with my cute dog, but I don't think I'll ever be able to walk with her again."

"You're right," she said. "I'm going to have to get used to it. I
```



### å•ä¸ªè¾“å…¥ä¸€æ¬¡æ€§ç”Ÿæˆå¤šä¸ªç»“æœ

é€šè¿‡è®¾ç½® num_return_sequencesï¼Œå¯ä»¥è·å¾—å¤šä¸ªç»“æœåºåˆ—ï¼Œè¿™é€‚ç”¨äº **beam search å’Œé‡‡æ ·æ–¹æ³•**ã€‚

**æ³¨æ„é»˜è®¤æƒ…å†µä¸‹ï¼Œgenerate ä½¿ç”¨è´ªå©ªæœç´¢ï¼Œå®ƒåªä¼šæœ‰ä¸€ä¸ªé¢„æµ‹ç»“æœï¼Œå› æ­¤æ— è®º num_return_sequences çš„å€¼æ˜¯å¤šå°‘ï¼Œéƒ½ä¼šå¾—åˆ°ç›¸åŒçš„åºåˆ—ã€‚**

```python
# activate beam search and early_stopping
beam_output = model.generate(
    **model_inputs,
    max_new_tokens=40,
    num_beams=5,
    no_repeat_ngram_size=2, 
    num_return_sequences=5, 
    early_stopping=True
)

token_ids = torch.squeeze(beam_output[0])
for j in range(token_ids.shape[0]):
    print(tokenizer.decode(token_ids[j], skip_special_tokens=True))
    print(20*'=')
```



```python
I enjoy walking with my cute dog, but I'm not sure if I'll ever be able to walk with him again.

I've been thinking about this for a while now, and I think it's time for me to
====================
I enjoy walking with my cute dog, but I'm not sure if I'll ever be able to walk with her again.

I've been thinking about this for a while now, and I think it's time for me to
====================
I enjoy walking with my cute dog, but I'm not sure if I'll ever be able to walk with him again.

I've been thinking about this for a while now, and I think it's a good idea to
====================
I enjoy walking with my cute dog, but I'm not sure if I'll ever be able to walk with him again.

I've been thinking about this for a while now, and I think it's time to take a
====================
I enjoy walking with my cute dog, but I'm not sure if I'll ever be able to walk with him again.

I've been thinking about this for a while now, and I think it's a good idea.
====================
```



é«˜è´¨é‡çš„äººç±»è¯­è¨€å¹¶ä¸éµå¾ªé«˜æ¦‚ç‡ä¸‹ä¸€è¯çš„åˆ†å¸ƒã€‚

æ¢å¥è¯è¯´ï¼Œä½œä¸ºäººç±»ï¼Œæˆ‘ä»¬å¸Œæœ›ç”Ÿæˆçš„æ–‡æœ¬èƒ½å¤Ÿå¸¦æ¥æƒŠå–œï¼Œè€Œä¸æ˜¯æ— èŠæˆ–å¯é¢„æµ‹çš„ã€‚å› **æ­¤æ¦‚ç‡æœ€ä¼˜å¹¶ä¸æ˜¯å¾ˆå¥½çš„ç­–ç•¥ï¼Œä½†è¿™ä¸ä»£è¡¨æˆ‘ä»¬åº”è¯¥é€‰æ‹©æ¦‚ç‡å¾ˆå°çš„è¯ï¼Œæˆ‘ä»¬è¦åœ¨è¿™ä¸¤è€…é—´å¹³è¡¡ä¸‹**ã€‚



## éšæœºç­–ç•¥ï¼ˆæ¦‚ç‡é‡‡æ ·ï¼‰

### top-ké‡‡æ ·

åœ¨ top-ké‡‡æ ·ä¸­ï¼Œ**æ¨¡å‹ä¼šç­›é€‰å‡º k ä¸ªæœ€å¯èƒ½çš„ä¸‹ä¸€ tokenï¼Œå¹¶å°†æ¦‚ç‡è´¨é‡é‡æ–°åˆ†é…åˆ°è¿™ K ä¸ªtokenï¼Œç„¶ååœ¨ä»–ä»¬ä¹‹ä¸­éšæœºé‡‡æ ·**ã€‚

1. **è®¡ç®—tokenæ¦‚ç‡**ï¼šåœ¨æ¨¡å‹å¤„ç†è¾“å…¥æ–‡æœ¬åï¼Œå®ƒä¼šé¢„æµ‹å¯èƒ½çš„ä¸‹ä¸€ä¸ª token çš„æ¦‚ç‡åˆ†å¸ƒã€‚
2. **ç­›é€‰ top-k**ï¼šä¸è€ƒè™‘æ‰€æœ‰å¯èƒ½çš„ token ä¸åŒï¼Œtop-k é‡‡æ ·**å°†é€‰æ‹©èŒƒå›´ç¼©å°åˆ°æ¦‚ç‡æœ€é«˜çš„ k ä¸ª token** ã€‚è¿™ç§â€œå‰ªæâ€å‡å°‘äº†æ½œåœ¨è¾“å‡ºç©ºé—´ï¼Œä¸“æ³¨äºæœ€å¯èƒ½çš„ä¸‹ä¸€ token ï¼Œè€Œå¿½ç•¥äº†ä¸å¤ªå¯èƒ½çš„é€‰é¡¹ã€‚
3. **éšæœºé‡‡æ ·**ï¼šä» top-k token ä¸­ï¼Œ**é‡æ–°åˆ†é…ä»–ä»¬çš„æ¦‚ç‡**ï¼ˆé»˜è®¤å¹³ç­‰æ¦‚ç‡ï¼‰ï¼Œæ ¹æ®å®ƒä»¬çš„æ¦‚ç‡éšæœºé‡‡æ ·ä¸€ä¸ª token ï¼Œè€Œä¸æ˜¯æ€»æ˜¯é€‰æ‹©æœ€é«˜æ¦‚ç‡çš„è¯å…ƒã€‚è¿™ç§æ–¹å¼å¼•å…¥äº†å¤šæ ·æ€§ï¼Œä½¿ç”Ÿæˆçš„æ–‡æœ¬æ›´åŠ ä¸°å¯Œå¤šæ ·ã€‚
4. **æ§åˆ¶è¾“å‡ºå¤šæ ·æ€§**ï¼šé€šè¿‡è°ƒæ•´ k çš„å€¼ï¼Œé«˜ k å€¼ï¼ˆä¾‹å¦‚ 50 æˆ– 100ï¼‰å…è®¸æ›´å¤šçš„é€‰æ‹©ï¼Œå¢åŠ äº†å¤šæ ·æ€§å’Œåˆ›é€ æ€§ï¼Œä½†å¯èƒ½é™ä½è¿è´¯æ€§ã€‚ä½ k å€¼ï¼ˆä¾‹å¦‚ 5 æˆ– 10ï¼‰é™åˆ¶äº†é€‰é¡¹ï¼Œé€šå¸¸ä½¿æ–‡æœ¬æ›´å…·ç¡®å®šæ€§å’Œé›†ä¸­æ€§ï¼Œä½†æœ‰æ—¶ä¹Ÿä¼šå¯¼è‡´å†…å®¹è¿‡äºé‡å¤æˆ–ä¿å®ˆã€‚

top-k é‡‡æ ·é€šè¿‡ç›´æ¥å‰”é™¤æ¦‚ç‡è¾ƒä½çš„è¯å…ƒï¼Œé™åˆ¶æ¨¡å‹ä»æ¦‚ç‡æœ€é«˜çš„å‰ k ä¸ªè¯å…ƒä¸­è¿›è¡Œé‡‡æ ·ã€‚ä¾‹å¦‚ï¼Œè‹¥ä½¿ç”¨ top-3 é‡‡æ ·ï¼Œæ¨¡å‹å°†ä»…ä»æ¦‚ç‡æœ€å¤§çš„ä¸‰ä¸ªè¯å…ƒä¸­è¿›è¡Œé‡‡æ ·ã€‚

```python
topk_output = model.generate(**model_inputs, 
    max_new_tokens=40,
    do_sample=True, 
    top_k=50
    )

token_ids = torch.squeeze(topk_output[0])
print(tokenizer.decode(token_ids, skip_special_tokens=True))
```



```python
I enjoy walking with my cute dog Molly. We share a bit and we're sure we'll be spending a lot less.

I always have the sneaking suspicion that sometimes pets get a bit petty, but it turns out
```



ç„¶è€Œï¼Œtop-ké‡‡æ ·çš„ä¸€ä¸ªé—®é¢˜æ˜¯ï¼Œå®ƒä¸ä¼šåŠ¨æ€è°ƒæ•´ä»ä¸‹ä¸€ä¸ª token çš„æ¦‚ç‡åˆ†å¸ƒä¸­è¿‡æ»¤çš„ token ã€‚è¿™å¯èƒ½ä¼šå¯¼è‡´é—®é¢˜ï¼Œå› ä¸ºæŸäº› token å¯èƒ½æ¥è‡ªéå¸¸é™¡å³­çš„åˆ†å¸ƒï¼ˆå³**é›†ä¸­äºå°‘æ•°è¯çš„åˆ†å¸ƒï¼Œè¿™æ—¶æ›´å®¹æ˜“åŠ å…¥å¾ˆä½æ¦‚ç‡çš„ token ï¼Œä¿ç•™ä»–ä»¬çš„æ„ä¹‰ä¸å¤§**ï¼‰ï¼Œè€Œå…¶ä»–è¯åˆ™æ¥è‡ªæ›´å¹³å¦çš„åˆ†å¸ƒï¼ˆè¿™ç§æƒ…å†µ token çš„é€‰æ‹©æ›´æ­£å¸¸ï¼‰ã€‚

å› æ­¤ï¼Œå°†é‡‡æ ·æ± é™åˆ¶ä¸ºå›ºå®šå¤§å° k å¯èƒ½ä¼šå¯¼è‡´æ¨¡å‹åœ¨é™¡å³­åˆ†å¸ƒä¸­äº§ç”Ÿæ— æ„ä¹‰çš„å†…å®¹ï¼Œè€Œåœ¨å¹³å¦åˆ†å¸ƒä¸­é™åˆ¶æ¨¡å‹çš„åˆ›é€ åŠ›ã€‚

### top-pé‡‡æ ·

ä¸ä»…ä»æœ€å¯èƒ½çš„ k ä¸ª token ä¸­é‡‡æ ·ä¸åŒï¼Œtop-p é‡‡æ ·é€‰æ‹©çš„æ˜¯**ç´¯è®¡æ¦‚ç‡è¶…è¿‡é˜ˆå€¼ p çš„æœ€å° token é›†åˆ**ã€‚

å®ƒä¸ top-k çš„åŒºåˆ«ä»…åœ¨äºç­›é€‰æ–¹å¼ã€‚top-k é‡‡æ ·é€‰æ‹©ä¸ªä½“æ¦‚ç‡æœ€é«˜çš„å‰ k ä¸ª token ï¼Œè€Œ top-p é‡‡æ ·åˆ™è€ƒè™‘ç´¯è®¡æ¦‚ç‡è‡³å°‘ä¸º p çš„æœ€å° token é›†åˆï¼Œå³æ¦‚ç‡è¾ƒå¤§çš„é‚£äº› token ã€‚

ç”±äº top-k é‡‡æ ·ç­–ç•¥å¹¶ä¸è€ƒè™‘æ•´ä½“æ¦‚ç‡åˆ†å¸ƒï¼Œ å› æ­¤å›ºå®šçš„å¸¸æ•° *ğ‘˜* å¯èƒ½æ— æ³•é€‚åº”ä¸åŒçš„ä¸Šä¸‹æ–‡è¯­å¢ƒã€‚ Top-p é‡‡æ ·ï¼ˆåˆç§°æ ¸é‡‡æ ·ï¼‰ä»ç¬¦åˆç‰¹å®šæ¦‚ç‡æ¡ä»¶çš„æœ€å°è¯å…ƒé›†åˆä¸­è¿›è¡Œé‡‡æ ·ï¼Œè¦æ±‚è¯¥é›†åˆä¸­æ‰€æœ‰è¯å…ƒçš„ç´¯ç§¯æ¦‚ç‡å¤§äºæˆ–ç­‰äºé¢„è®¾é˜ˆå€¼ pã€‚å…¶å…·ä½“å®ç°æ­¥éª¤ä¸ºï¼š

1. æŒ‰ç”Ÿæˆæ¦‚ç‡å¯¹è¯å…ƒè¿›è¡Œæ’åºï¼›
2. ä¸æ–­å°†è¯å…ƒæ·»åŠ åˆ°ä¸´æ—¶é›†åˆï¼Œç›´åˆ°é›†åˆçš„ç´¯ç§¯æ¦‚ç‡é¦–æ¬¡è¶…è¿‡é˜ˆå€¼ pã€‚

```python
topp_output = model.generate(**model_inputs, 
    max_new_tokens=40,
    do_sample=True, 
    top_p=0.92
    )

token_ids = torch.squeeze(topp_output[0])
print(tokenizer.decode(token_ids, skip_special_tokens=True))
```



```python
I enjoy walking with my cute dog and she is so much fun. She always is happy to meet my furry friends. She has a very friendly, warm, friendly demeanor and she likes playing with my pet! I am a huge fan
```



åœ¨å¼€æ”¾å¼è¯­è¨€ç”Ÿæˆä¸­ï¼Œtop-p å’Œ top-k é‡‡æ ·ä¼¼ä¹æ¯”ä¼ ç»Ÿçš„è´ªå¿ƒæœç´¢å’Œ beam search ç”Ÿæˆæ›´æµç•…çš„æ–‡æœ¬ã€‚ä½†æœ‰äººè¯æ˜ï¼Œè´ª**å¿ƒæœç´¢å’Œ beam search çš„æ˜æ˜¾ç¼ºé™·ï¼ˆä¸»è¦æ˜¯ç”Ÿæˆé‡å¤è¯åºåˆ—ï¼‰æ˜¯ç”±æ¨¡å‹æœ¬èº«ï¼ˆå°¤å…¶æ˜¯æ¨¡å‹çš„è®­ç»ƒæ–¹å¼ï¼‰å¼•èµ·çš„ï¼Œè€Œä¸æ˜¯ç”Ÿæˆæ–¹æ³•çš„é—®é¢˜**ã€‚

### temperature

é‡‡æ ·æ–¹æ³•è¿‡ç¨‹ä¸­éƒ½æ¶‰åŠåˆ°å¯¹éƒ¨åˆ†æ•°æ®é‡‡æ ·ï¼Œä½†é€šå¸¸éƒ½ä¼šæŠŠä»–ä»¬åŸå§‹çš„æ¦‚ç‡è¿›è¡Œè°ƒæ•´ã€‚æ¦‚ç‡è°ƒæ•´æ—¶çš„é‡è¦å‚æ•°å°±æ˜¯ **temperatureï¼Œå®ƒåœ¨æ–‡æœ¬ç”Ÿæˆä¸­ç”¨äºæ§åˆ¶ç”Ÿæˆå†…å®¹çš„éšæœºæ€§æˆ–åˆ›é€ æ€§ã€‚é€šè¿‡è°ƒæ•´å¯èƒ½ç”Ÿæˆçš„ä¸‹ä¸€ä¸ª token çš„æ¦‚ç‡åˆ†å¸ƒï¼Œtemperature å‚æ•°å¯ä»¥è®©æ¨¡å‹ç”Ÿæˆçš„æ–‡æœ¬æ›´ä¿å®ˆæˆ–æ›´å…·æœ‰åˆ›æ„**ã€‚

æ¸©åº¦ï¼ˆTï¼‰é€šè¿‡åœ¨åº”ç”¨softmaxä¹‹å‰å°†æ¯ä¸ªlogité™¤ä»¥Tæ¥è°ƒæ•´softmaxå‡½æ•°ï¼š

<img src="./assets/59e940e0cfb0489e854827e5bae9ab30.png" alt="img" style="zoom:50%;" />

1. **è°ƒæ•´æ¦‚ç‡åˆ†å¸ƒ**ï¼š
   - temperature ä¼šå¯¹æ¯ä¸ªå¯èƒ½ç”Ÿæˆçš„ä¸‹ä¸€ä¸ª token çš„æ¦‚ç‡åˆ†å¸ƒè¿›è¡Œç¼©æ”¾ã€‚**temperature è¶Šé«˜**ï¼Œåˆ†å¸ƒè¶Šâ€œå¹³â€ï¼Œå³æ¨¡å‹å¯¹æ¯ä¸ªå€™é€‰ token çš„é€‰æ‹©å€¾å‘æ€§é™ä½ï¼Œæ›´å¯èƒ½ä»æ›´å¤§èŒƒå›´çš„ token ä¸­éšæœºé€‰å–ä¸‹ä¸€ä¸ª token ã€‚
   - **temperature è¶Šä½**ï¼Œåˆ†å¸ƒè¶Šâ€œå°–â€ï¼Œæ¨¡å‹ä¼šæ›´åå‘é€‰æ‹©é«˜æ¦‚ç‡çš„å€™é€‰ token ï¼Œè¿™æ ·ç”Ÿæˆçš„æ–‡æœ¬å°±ä¼šæ›´å¯é¢„æµ‹å’Œè¿è´¯ã€‚
2. **å–å€¼èŒƒå›´**ï¼š
   - **temperature = 1.0**ï¼šé»˜è®¤è®¾ç½®ï¼Œä¸å¯¹åˆ†å¸ƒåšä»»ä½•è°ƒæ•´ã€‚
   - **temperature < 1.0**ï¼ˆå¦‚ 0.7ï¼‰ï¼štemperature è¾ƒä½æ—¶ï¼Œæ¨¡å‹ä¼šæ›´â€œä¿å®ˆâ€ï¼Œæ›´å€¾å‘äºé€‰æ‹©æ¦‚ç‡è¾ƒé«˜çš„è¯ã€‚ç”Ÿæˆçš„æ–‡æœ¬é€šå¸¸æ›´è¿è´¯ï¼Œé‡å¤æ€§è¾ƒé«˜ã€‚
   - **temperature > 1.0**ï¼ˆå¦‚ 1.5ï¼‰ï¼štemperature è¾ƒé«˜æ—¶ï¼Œæ¨¡å‹ä¼šæ›´â€œå¤§èƒ†â€ï¼Œæ›´å¯èƒ½ç”Ÿæˆè¾ƒä¸ºæ„å¤–æˆ–æœ‰åˆ›æ„çš„å†…å®¹ï¼Œä½†åŒæ—¶ä¹Ÿä¼šå¢åŠ ç”Ÿæˆå‡ºä¸è¿è´¯å†…å®¹çš„é£é™©ã€‚
3. **ä½¿ç”¨ä¸åŒ temperature çš„åœºæ™¯**ï¼š
   - **ä½æ¸©ï¼ˆ0.2-0.7ï¼‰**ï¼šé€‚åˆç”¨äºäº‹å®æ€§å›ç­”ï¼Œæˆ–éœ€è¦ç²¾å‡†å’Œå¯é¢„æµ‹çš„åœºæ™¯ã€‚
   - **é«˜æ¸©ï¼ˆ1.2-1.5ï¼‰**ï¼šé€‚åˆç”¨äºåˆ›æ„æ€§ä»»åŠ¡ï¼Œæ¯”å¦‚å†™æ•…äº‹æˆ–å¼€æ”¾å¼å¯¹è¯ï¼Œé€‚åˆéœ€è¦å¤šæ ·æ€§å’Œç‹¬ç‰¹æ€§çš„åœºæ™¯ã€‚

è¿™é‡Œ temperature å’Œç”Ÿæˆçš„å…³ç³»ç±»ä¼¼äºæ¸©åº¦å¯¹åˆ†å­æ´»åŠ¨çš„å½±å“ï¼Œæ¸©åº¦è¶Šé«˜åˆ†å­æ´»åŠ¨è¶Šæ´»æ³¼ï¼Œåä¹‹è¶Šå†·æ·¡ã€‚

# pipelineæ‰¹é¢„æµ‹

è¿™æ˜¯å•ä¸ªæ•°æ®çš„ç”Ÿæˆï¼Œä¸generateå‡½æ•°æœ‰ç€ç›¸åŒçš„å‚æ•°ã€‚

```python
import os
import json
import torch
import argparse
from tqdm import tqdm
from pprint import pprint
from transformers import pipeline

from transformers import AutoTokenizer, AutoModelForCausalLM

DEVICE = torch.device("cuda:7" if torch.cuda.is_available() else "cpu")


# local_cache_dir is for mannually downloading model params to local env
local_cache_dir = "../../DataCollection/officials/gpt2"

pipe = pipeline(task='text-generation', model=local_cache_dir, device=DEVICE)

if not pipe.tokenizer.pad_token_id:
    pipe.tokenizer.pad_token_id = pipe.tokenizer.eos_token_id

result = pipe("Once upon a time", 
            max_new_tokens=50, 
            # top_k=50, 
            top_p=0.92,
            temperature=0.7,
            num_return_sequences=2,
            )
for item in result:
    print(item['generated_text'])
    print(20*'=')
```



æ‰¹é‡é¢„æµ‹

```python
prompts = ["The future of technology is", "Once upon a time in a distant land", "Artificial intelligence has changed"]
results = pipe(prompts, max_length=50, batch_size=8)

for idx, result in enumerate(results):
    print(f"Prompt {idx + 1}: {prompts[idx]}")
    print(result[0]['generated_text'])
    print(20*'=')
```



```python
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
Prompt 1: The future of technology is
The future of technology isThe future of technology is changing more quickly than ever. The ability to connect to your computer and get access to and manipulate your information is gaining momentum, and companies are starting to realize that it is extremely valuable.
====================
Prompt 2: Once upon a time in a distant land
Once upon a time in a distant land when I was a boy, my father asked me why I'd joined the British Army. I explained that it was for the military's own bad. I remember being in a room full of young men with red
====================
Prompt 3: Artificial intelligence has changed
Artificial intelligence has changedIt has become too big, too high and too expensive for our everyday lives, with the main goal of giving us all the tools we need for achieving our goals or making sure we're doing something good. For
====================
```

# å‚è€ƒ

https://blog.csdn.net/weixin_65514978/article/details/143059617

